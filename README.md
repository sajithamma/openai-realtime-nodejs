
# Real-time Audio Interaction with OpenAI WebSocket API

This sample code real-time audio interaction using OpenAI's WebSocket API for GPT-4o's real-time audio streaming preview. The system sends an input audio file to the OpenAI server and plays the audio response in real-time using Node.js.

## Overview

- **Input Audio**: The system reads an input audio file (e.g., `gettysburg.wav`), encodes it into base64 PCM16 format, and sends it to the OpenAI server.
- **Real-time Response**: The OpenAI server responds with real-time audio chunks, which are played directly from memory using the `speaker` library.
- **Real-time Playback**: The audio is played as it is received without needing to save the audio to a file.

## Prerequisites

- Node.js (v14+)
- OpenAI API Key
- An audio file in `.wav` format (mono, 16-bit PCM, sampled at 24,000 Hz)

## Installation

1. Clone the repository or download the project files:
   ```bash
   git clone git@github.com:sajithamma/openai-realtime-nodejs.git
   cd openai-realtime-nodejs
   ```

2. Install the dependencies:
   ```bash
   npm install
   ```

   This will install the following dependencies:
   - `dotenv`: To manage environment variables.
   - `speaker`: To play real-time audio from PCM16 data.
   - `audio-decode`: To decode the input audio file.
   - `ws`: WebSocket client for OpenAI's WebSocket API.

3. Add your OpenAI API key to a `.env` file:
   ```bash
   touch .env
   ```

   Add the following line to the `.env` file:
   ```bash
   OPENAI_API_KEY=your-openai-api-key-here
   ```

## Running the Project

1. Place your input `.wav` audio file in the project directory. Ensure the file is mono, 16-bit PCM, sampled at 24,000 Hz. For example, `gettysburg.wav`.

2. Run the project:
   ```bash
   node app.mjs
   ```

3. The program will:
   - Read and encode the input audio file.
   - Send the input audio to OpenAI’s WebSocket API.
   - Play the response audio in real-time using your system's speaker.

## Project Structure

```plaintext
.
├── app.mjs               # Main entry point of the app
├── package.json         # Project dependencies and scripts
├── .env                 # OpenAI API key (not included in the repo)
└── gettysburg.wav       # Input audio file (add your own)
```

## Expected Output

1. **Console Output**: As the program runs, you will see WebSocket events being printed in the console. Example:
   ```plaintext
   Connected to server.
   Message received from server: { type: 'response.audio.delta', ... }
   Appending 12345 bytes to speaker...
   Message received from server: { type: 'response.audio.done', ... }
   Audio generation done.
   ```

2. **Real-time Audio Playback**: You will hear the real-time response generated by the OpenAI server through your speakers as audio chunks are received.

## Troubleshooting

1. **Slow Audio**: If the audio sounds slowed down, ensure that the sample rate of the input file is 24,000 Hz. The response audio is played assuming this rate.
2. **No Audio**: Make sure your system's audio is working and the correct audio device is selected. Also, ensure the input audio file is in the correct format.

